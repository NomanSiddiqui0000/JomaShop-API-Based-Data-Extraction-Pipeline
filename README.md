# Jomashop Product Scraper ğŸ›ï¸

![Node.js](https://img.shields.io/badge/Node.js-18.x-green) 
![MongoDB](https://img.shields.io/badge/MongoDB-7.x-brightgreen) 
![Web Scraping](https://img.shields.io/badge/Web--Scraping-blue)

A professional-grade Node.js solution for scraping and storing product data from [Jomashop.com](https://www.jomashop.com) with MongoDB integration.

---

## Features âœ¨

- **Pagination Support**: Automatically handles multi-page categories  
- **Rich Product Data**: Extracts pricing, images, descriptions, and metadata  
- **Anti-Detection Mechanisms**: Randomized delays & user-agent rotation  
- **Data Integrity**: MongoDB schema validation and duplicate prevention  
- **Error Resilience**: Comprehensive error handling and retry logic  

---

## Installation ğŸ’»

```bash
git clone https://github.com/NomanSiddiqui0000/JomaShop-API-Based-Data-Extraction-Pipeline
cd JomaShop Data Extraction Using API
npm install
```

---

## Configuration âš™ï¸

Start MongoDB locally:

```bash
mongod --dbpath=./data/db
```

Modify MongoDB connection in `dbsetup.js` if needed:

```javascript
await mongoose.connect('mongodb://127.0.0.1:27017/jomashop');
```

---

## Usage ğŸš€

```bash
node index.js
```

---

## Core Components ğŸ§©

| File                         | Description                                           |
|------------------------------|-------------------------------------------------------|
| `index.js`                   | Main orchestration script                             |
| `dbsetup.js`                 | MongoDB connection & schema definitions               |
| `getSingleProductDetail.js`  | Extracts detailed product information                 |
| `getSingleCatProductList.js` | Handles category pagination and product lists         |
| `delay.js`                   | Request throttling utilities                          |

---

## Data Model ğŸ“Š

```javascript
{
  id: Number,
  name: String,
  brandName: String,
  urlKey: String, // Unique identifier
  stockStatus: String,
  pricing: {
    regularPrice: { value: Number, currency: String },
    finalPrice: { value: Number, currency: String },
    retailPrice: { value: Number, currency: String }
  },
  productImages: [String],
  description: {
    short: String,
    complete: String
  },
  metaData: {
    metaTitle: String,
    metaKeywords: [String],
    metaDescription: String
  }
}
```

---

## Dependencies ğŸ“¦

```json
{
  "axios": "^1.7.9",
  "mongoose": "^8.9.6"
}
```

---

## Best Practices ğŸ”

- â³ Random delays between 500â€“2000ms (enable in `index.js`)  
- ğŸ”„ User-agent rotation for request diversity  
- ğŸ›¡ï¸ Respects websiteâ€™s `robots.txt` guidelines  
- ğŸš¦ Rate limiting to prevent server overload  

---

## Disclaimer âš ï¸

This project demonstrates web scraping concepts for **educational purposes only**. Always:

- âœ… Verify website terms of service  
- âœ… Use official APIs when available  
- âœ… Respect copyright and data  
- âœ… Limit request frequency to reasonable levels  

---

## License ğŸ“œ

**MIT License**

---

For optimal results, ensure:

1. A valid `package.json` with listed dependencies  
2. MongoDB is running locally (or update the connection string)  
3. Your repo follows the structure described above  
